@require: itemize
@import: local

let nlstar = '<
        +section?:(`sec:nlstar`) {NL\*アルゴリズム} <
            +dialog(
                [(Some({お母さん}),{「おばあちゃんが教えてくれたの!});
                 (None,{\skip(68pt);L\* が DFA しか学習できないのは悪魔のせいだって!});
                 (None,{　});
                 (None,{　          });
                 (Some({お母さん}), {「だからお母さん、エクソシストさんを呼んであげたのよ!});
                 (None,{\skip(68pt);必ず L\* で NFA を学習してくれるから!});
                 (None,{　});
                 (None,{　          });
                 (Some({明美}),{「勝手に非決定的分岐を必要としてるんじゃねえ!});
                 (None,{\skip(45pt);私は DFA で十分満足してるんだよ!});
                 (None,{　});
                 (None,{　          });
                 (Some({ガミジン}),{「その考え！人格がMyhill–Nerodeに支配されている！});]);
            +p {
               前節までに説明したIDアルゴリズムやL\*アルゴリズムでは正規言語${\Lg}を表現する最小DFAを学習します。
               一方でNFAを用いることで等価な正規言語を表現するオートマトンの状態数を指数的に小さくすることがあることが知られています。
               本節ではL\*アルゴリズムと同様に所属性質問と等価性質問を用いて、正規言語${\Lg}を表現するNFAを学習する、NL\*アルゴリズムを紹介します。
            }
   +subsection?:(`sec:RFSA`){Residual Finite-State Automata} <
            +p {
               IDアルゴリズムやL\*アルゴリズムで観察表からDFAを生成できたカラクリは、観察表が一貫していて閉じているとき、
               観察表は (学習したい言語とは限らない)ある正規言語のMyhill-Nerode同値関係を表現するので、これを用いてDFAを生成することができる、というものでした。
               同様に観察表を用いてNFAを学習しようとすると、何らかの方法でNFAを生成する必要がありますが、このままの「一貫」や「閉」の定義のままでは
               最終的にMyhill-Nerode同値関係が学習されてしまい、結局状態数を減らすことができません。
               NL\*アルゴリズムではIDアルゴリズムやL\*アルゴリズムで用いた「一貫」や「閉」の代わりに\emph{RFSA一貫(RFSA-Consistency)}と\emph{RFSA閉(RFSA-Closedness)}を用い、
               観察表からはDFAの代わりに\emph{residual finite-state automaton (RFSA)}と呼ばれるNFAのサブクラスを生成します。
               RFSAはDFAを含むNFAのサブクラスで、RFSAが表わす言語をDFAを用いて表わすと指数的に多くの状態数が必要となる場合があることが知られています。
               また、本章では省きますがRFSAにはDFAでの最小DFAと同じ様に、canonical RFSAと呼ばれるものが存在します。
               L\*アルゴリズムで最小DFAが学習されるのと対応して、
               NL\*アルゴリズムによって学習されるRFSAはcanonical RFSAになります。
               詳細は\cite([`conf/ijcai/BolligHKL09`]);を参照してください。
            }
            +definition ?:({residual言語}) ?:(`def:residual-language`) {
              言語${\Lg \subseteq \Word}及び${\word \in \Word}について、${\word^{-1}\Lg = \setsep{\word' \in \Word}{\word \word' \in \Lg}}と定義する。
              言語${\Lg'}と言語${\Lg}について文字列 ${\word \in \Word}で${\Lg' = \word^{-1}\Lg}を充たすものが存在するとき、${\Lg'}が${\Lg}の\emph{residual言語}であるという。
              言語${\Lg}のresidual言語の集合を${\Res{\Lg}}と表記する。
            }
            +definition ?:({residual finite-state automata (RFSA)}) ?:(`def:RFSA`) {
              NFA ${\A=\paren{\alphabet,\Loc,\InitLoc,\AccLoc,\Transition}}及び${\loc \in \Loc}について、
              ${\A_{\loc}=\paren{\alphabet,\Loc,\set{\loc},\AccLoc,\Transition}}及び${\Lg_{\loc} = \Lgof{\A_{\loc}}}と表記する。
              NFA ${\A=\paren{\alphabet,\Loc,\InitLoc,\AccLoc,\Transition}}及び任意の${\loc \in \Loc}について、
              ${\Lg_{\loc} \in \Res{\Lgof{\A}}}を充たすとき、${\A}が\emph{residual finite-state automaton}であるという。
            }
            +definition ?:({${\sqsubseteq, \sqcup}}) {
              ${P,P',S}を観察表${T}の添字集合とする。
              観察表${T}の行${T\[w,\text!{-}\]}と${T\[w',\text!{-}\]}について、
              任意の${u \in S}について${T\[w,u\] = \text!{+} \Rightarrow T\[w',u\] = \text!{+}}が成り立つとき、
              ${T\[w,\text!{-}\] \sqsubseteq T\[w',\text!{-}\]}と表記する。
              観察表${T}の行の添字${w,w',w'' \in P \cup P'}について、
              任意の${u \in S}について
              \eqn(${T\[w,u\] = \text!{+} \iff T\[w',u\] = \text!{+ または} T\[w'',u\] = \text!{+}});
              が成り立つとき、
              ${T\[w,\text!{-}\] = T\[w',\text!{-}\] \sqcup T\[w'',\text!{-}\]}と表記する。
              ${w \in P \cup P'}について、${w_1,w_2,\cdots,w_n \in \paren{P \cup P'}\setminus \set{w}}で
              \eqn(${T\[w,\text!{-}\] = \bigsqcup_{i \in \set{1,2,\cdots,n}} T\[w_i,\text!{-}\]});
              を充たすものが存在しないとき、行${T\[w,\text!{-}\]}を\emph{素}であるという。
              観察表${T}の素な添字集合を${\Primes{T} \subseteq P \cup P'}と表記する。
            }
            +definition ?:({RFSA一貫}) ?:(`def:RFSA-consistency`) {
              ${P,P',S}を観察表${T}の添字集合とする。
              任意の${w,w'\in P}、${a\in\alphabet}について、
              ${T\[w,\text!{-}\] \sqsubseteq T\[w',\text!{-}\]}ならば
              ${T\[w a,\text!{-}\] \sqsubseteq T\[w' a,\text!{-}\]}が成り立つとき、
              観察表${T}が\emph{RFSA一貫}であるという。
            }
            +definition ?:({RFSA閉}) ?:(`def:RFSA-closed`) {
              ${P,P',S}を観察表${T}の添字集合とする。
              任意の${w\in P'}について、
              ${T\[w,\text!{-}\] = \bigsqcup \setsep{T\[w',\text!{-}\]}{w' \in \Primes{T} \cap P,T\[w',\text!{-}\] \sqsubseteq T\[w,\text!{-}\]}}
              が成り立ち、
              任意の${w\in P}及び${a \in \alphabet}について、${w a \in P \cup P'}が成り立つとき、
              観察表${T}が\emph{RFSA閉}であるという。
            }
        >
   +subsection?:(`subsec:NLstar`){NL\*アルゴリズム} <
   +p {
     \figure ?:(`fig:mustFinishKBFM1`){本章で学習するNFA。DFAに変換すると状態数が増加する。}<
          +image-frame{\insert-pdf-image(7cm)(path-to-root ^ `figs/mustFinishKBFM1.pdf`)(1);}
      >
   本節では例として、\ref-figure(`fig:mustFinishKBFM1`);のNFAが認識する言語${\Lg}を用いてNL\*アルゴリズムの動作を見ていきます。
   }
+p {
  \figure ?:(`fig:NLStarObservationTable1`){一番始めの観察表(左)と所属性神託を使って内容を埋めた観察表(右)}<
  +left-right{\observationTable(
    [[{} ;{${\epsilon}} ;];
     [{${\epsilon}};];
     [{—————};{—————};];]);}{
\observationTable(
    [[{} ;{${\epsilon}} ;];
     [{${\epsilon}};{-};];
     [{—————};{—————};];
     [{K};{-};];
     [{B};{-};];
     [{F};{-};];]);
 }
>
  NL\*アルゴリズムでも、L\*アルゴリズムと同様にまず始めに\ref-figure(`fig:NLStarObservationTable1`);左の観察表から始めます。最初に空欄になっているセル${T\[\epsilon, \epsilon\]}を所属性質問を用いて埋め、同時に${P'}にK,B,Fを追加し、同様に埋めます (\ref-figure(`fig:NLStarObservationTable1`);右) 。
  ここで\ref-figure(`fig:NLStarObservationTable1`);右の観察表がRFSA閉であるかを判定します。
  今回は任意の${w\in P'}について、${T\[w,\text!{-}\]=T\[\epsilon,\text!{-}\]}が成り立ちますし、各${a\in\alphabet}について、${a\in P'}が成り立つので観察表は閉じています。
  }
+p{
  \figure ?:(`fig:mustFinishKBFM1Step1`){\ref-figure(`fig:NLStarObservationTable1`);右の観察表に対応するRFSA ${\A_1}}<
     +image-frame{\insert-pdf-image(5cm)(path-to-root ^ `figs/KBFStep1.pdf`)(1);}
  >
  \figure ?:(`fig:NLStarObservationTable2`){K、KB、KBF、KBFKを${S}に追加した観察表}<
    +centering{
      \observationTable([
        [{} ;{${\epsilon}} ;{K};{KB};{KBF};{KBFK};];
        [{${\epsilon}};{-};{-};{-};{-};{+};];
        [{—————};{—————};{—————};{—————};{—————};{—————};];
        [{K};{-};{-};{-};{+};{+};];
        [{B};{-};{-};{-};{-};{+};];
        [{F};{-};{-};{-};{-};{+};]
      ]);
    }
  >
}
  +p {
  観察表がRFSA閉である場合、観察表からRFSAを生成します。
  観察表からRFSAを生成する方法は以下の様に、IDアルゴリズムでDFAを生成した方法と似ています。
  \listing{
* 各${\word \in P \cap \Primes{T}}に対して、RFSAの状態${\loc_\word}を生成する
* RFSAの初期状態は${\InitLoc = \setsep{\loc_\word}{\loc_\word \in \Loc, T\[\word,\text!{-}\] \sqsubseteq T\[\epsilon,\text!{-}\]}}とする。
* RFSAの受理状態は${\AccLoc = \setsep{\loc_\word}{\loc_\word \in \Loc, T\[\word,\epsilon\] = \text!{+}}}とする。
* RFSAの遷移関係${\Transition \subseteq \Loc \times \alphabet \times \Loc}は、${\Transition = \setsep{\paren{\loc_{\word},a,\loc_{\word'}}}{T\[\word',\text!{-}\] \sqsubseteq T\[\word a,\text!{-}\]}}とする。
}
  \ref-figure(`fig:NLStarObservationTable1`);右の観察表からは\ref-figure(`fig:mustFinishKBFM1Step1`);のRFSA、${\A_1}が生成されます。
}
 +p{
  RFSA ${\A_1}を生成することができたので等価性質問によって、RFSA ${\A_1}が学習したい正規言語を認識するかどうかを調べてみます。
  今回、RFSA ${\mathcal{A}_1}は言語${\Lg}を認識しないので、最短の反例 KBFK が返ります。
  ここで、${S}にKBFKのsuffixで${S}に含まれていないものを追加します。
  KBFKのsuffixは${\epsilon}、K、FK、BFK、KBFKなので、今回は${S}にK、FK、BFK、KBFKを追加し、観察表を埋めます。 (\ref-figure(`fig:NLStarObservationTable2`);)
}
%      page-break page pagecontf pagepartsf (bb-toc +++ bb-main)        
+p{
\figure ?:(`fig:NLStarObservationTable3`){Kを${P}に、KK、KB、KFを${P'}に追加した観察表}<
+centering{
  \observationTable(
    [[{} ;{${\epsilon}} ;{K};{FK};{BFK};{KBFK};];
     [{${\epsilon}};{-};{-};{-};{-};{+};];
     [{K};{-};{-};{-};{+};{+};];
     [{—————};{—————};{—————};{—————};{—————};{—————};];
     [{B};{-};{-};{-};{-};{+};];
     [{F};{-};{-};{-};{-};{+};];
     [{KK};{-};{-};{-};{+};{+};];
     [{KB};{-};{-};{+};{-};{+};];
     [{KF};{-};{-};{-};{-};{+};]]);
}
>
  \figure ?:(`fig:NLStarObservationTable4`){KBを${P}に、KBK、KBB、KBFを${P'}に追加した観察表}<
+centering{
  \observationTable(
    [[{} ;{${\epsilon}} ;{K};{FK};{BFK};{KBFK};];
     [{${\epsilon}};{-};{-};{-};{-};{+};];
     [{K};{-};{-};{-};{+};{+};];
     [{KB};{-};{-};{+};{-};{+};];
     [{—————};{—————};{—————};{—————};{—————};{—————};];
     [{B};{-};{-};{-};{-};{+};];
     [{F};{-};{-};{-};{-};{+};];
     [{KK};{-};{-};{-};{+};{+};];
     [{KF};{-};{-};{-};{-};{+};];
     [{KBK};{-};{-};{+};{+};{+};];
     [{KBB};{-};{-};{-};{-};{+};];
     [{KBF};{-};{+};{-};{-};{+};]]);
}
>
  \figure ?:(`fig:NLStarObservationTable5`){KBFを${P}に、KBFK、KBFB、KBFFを${P'}に追加した観察表}<
+centering{
  \observationTable(
    [[{} ;{${\epsilon}} ;{K};{FK};{BFK};{KBFK};];
     [{${\epsilon}};{-};{-};{-};{-};{+};];
     [{K};{-};{-};{-};{+};{+};];
     [{KB};{-};{-};{+};{-};{+};];
     [{KBF};{-};{+};{-};{-};{+};];
     [{—————};{—————};{—————};{—————};{—————};{—————};];
     [{B};{-};{-};{-};{-};{+};];
     [{F};{-};{-};{-};{-};{+};];
     [{KK};{-};{-};{-};{+};{+};];
     [{KF};{-};{-};{-};{-};{+};];
     [{KBK};{-};{-};{+};{+};{+};];
     [{KBB};{-};{-};{-};{-};{+};];
     [{KBFK};{+};{-};{-};{+};{+};];
     [{KBFB};{+};{-};{-};{-};{+};];
     [{KBFF};{+};{-};{-};{-};{+};]]);
}
>}
+p{
  \ref-figure(`fig:NLStarObservationTable2`);の観察表は閉じていないので、\ref-figure(`fig:NLStarObservationTable2`);の観察表が閉じるまで${P}及び${P'}に文字列を追加し、観察表を埋めます。 (\ref-figure(`fig:NLStarObservationTable3`);\ref-figure(`fig:NLStarObservationTable4`);\ref-figure(`fig:NLStarObservationTable5`);\ref-figure(`fig:NLStarObservationTable6`);)
}
+p {
  \figure ?:(`fig:NLStarObservationTable6`){KBFBを${P}に、KBFBK、KBFBB、KBFBFを${P'}に追加した観察表。この観察表はRSFA閉である}<
+centering{
  \observationTable(
    [[{} ;{${\epsilon}} ;{K};{FK};{BFK};{KBFK};];
     [{${\epsilon}};{-};{-};{-};{-};{+};];
     [{K};{-};{-};{-};{+};{+};];
     [{KB};{-};{-};{+};{-};{+};];
     [{KBF};{-};{+};{-};{-};{+};];
     [{KBFB};{+};{-};{-};{-};{+};];
     [{—————};{—————};{—————};{—————};{—————};{—————};];
     [{B};{-};{-};{-};{-};{+};];
     [{F};{-};{-};{-};{-};{+};];
     [{KK};{-};{-};{-};{+};{+};];
     [{KF};{-};{-};{-};{-};{+};];
     [{KBK};{-};{-};{+};{+};{+};];
     [{KBB};{-};{-};{-};{-};{+};];
     [{KBFK};{+};{-};{-};{+};{+};];
     [{KBFF};{+};{-};{-};{-};{+};];
     [{KBFBK};{-};{-};{-};{+};{+};];
     [{KBFBB};{-};{-};{-};{-};{+};];
     [{KBFBF};{-};{-};{-};{-};{+};]]);
}
>
}
+p {
  \figure ?:(`fig:mustFinishKBFM1Step2`){\ref-figure(`fig:NLStarObservationTable6`);の観察表に対応するRFSA ${\A_2}}<
     +image-frame{\insert-pdf-image(12cm)(path-to-root ^ `figs/mustFinishKBFM1Step2.pdf`)(1);}
  >
  最後に\ref-figure(`fig:NLStarObservationTable6`);の観察表に対応するRFSA ${\A_2}を生成し、等価性質問によって${\Lgof{\A_2}}と学習したい正規言語が一致するかどうかを調べます。
  今回は${\Lgof{\A_2}}が学習したい正規言語と一致するので、NL\*アルゴリズムはここで終了となります。
}
+p{
  ${\A_2}は\ref-figure(`fig:mustFinishKBFM1`);のNFAとは違ったNFAですが、認識する言語は等しいです。さらに、遷移関係の個数は多いですが、状態数は\ref-figure(`fig:mustFinishKBFM1`);のNFAと同じで、同じ言語を認識する最小DFAより小さいです。
}
  >
  +subsection{L\*アルゴリズムとの関係} <
  +p{
  L\*アルゴリズムでの「閉」や「一貫」の定義はRFSA閉やRFSA一貫より強いので、
  L\*アルゴリズムの意味で閉じていて一貫している観察表は
  NL\*アルゴリズムの意味でも閉じていて一貫しています。
  また、NL\*アルゴリズムでの観察表${T}について、${T}がRFSA閉かつRFSA一貫なとき、
  ${\word,\word' \in \Word}が
  ${\word \MNRel{L} \word'}を充たす
  なら${\word}と${\word'}の少なくとも一つは素ではないので、${T}から生成されたRFSAは同じ言語を認識する最小DFAと状態数が同じか少なくなります。
  }
  +p {
  本章では学習についての計算量解析や性能比較は基本的には省略するので、\cite([`conf/ijcai/BolligHKL09`]);を参照してください。
  NL\*アルゴリズムでは所属性質問や等価性質問を行った直後に、素な添字の個数が減ることもあるので、停止性証明や計算量解析はやや込み入っています。
  また、計算量、つまり学習したい正規言語を学習するのに必要な所属性質問や等価性質問の回数を比較すると、最悪の場合はNL\*アルゴリズムの方がL\*アルゴリズムよりも多くなることが知られています。
  一方で実験的にはL\*アルゴリズムと比べて、NL\*アルゴリズムはむしろ高速に動作することが報告されています。
  さらに、NL\*アルゴリズムで学習されるRFSAは、最小DFAと比較してかなり状態数が小さくなることも、実験的に報告されています。
  }
  >
  >
>